{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "\n",
    "# 脸\n",
    "FACE_POINTS = list(range(17, 68))\n",
    "# 嘴巴\n",
    "MOUTH_POINTS = list(range(48, 61))\n",
    "# 右眉毛\n",
    "RIGHT_BROW_POINTS = list(range(17, 22))\n",
    "# 左眉毛\n",
    "LEFT_BROW_POINTS = list(range(22, 27))\n",
    "# 右眼\n",
    "RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "# 左眼\n",
    "LEFT_EYE_POINTS = list(range(42, 48))\n",
    "# 鼻子\n",
    "NOSE_POINTS = list(range(27, 35))\n",
    "# 下巴\n",
    "JAW_POINTS = list(range(0, 17))\n",
    "\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "\n",
    "def GetLandmarks(img_path):\n",
    "\timg = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "\trects = detector(img, 1)\n",
    "\tif len(rects) > 1:\n",
    "\t\tprint('[Warning]: More than one face in picture, only choose one randomly...')\n",
    "\t\trects = rects[0]\n",
    "\telif len(rects) == 0:\n",
    "\t\tprint('[Error]: No face detected...')\n",
    "\t\treturn None\n",
    "\treturn img, np.matrix([[p.x, p.y] for p in predictor(img, rects[0]).parts()])\n",
    "\n",
    "\n",
    "# refer:\n",
    "# \thttps://en.wikipedia.org/wiki/Procrustes_analysis#Ordinary_Procrustes_analysis\n",
    "def TransferPoints(points1, points2):\n",
    "\tpoints1 = points1.astype(np.float64)\n",
    "\tpoints2 = points2.astype(np.float64)\n",
    "\tc1 = np.mean(points1, axis=0)\n",
    "\tc2 = np.mean(points2, axis=0)\n",
    "\tpoints1 -= c1\n",
    "\tpoints2 -= c2\n",
    "\ts1 = np.std(points1)\n",
    "\ts2 = np.std(points2)\n",
    "\tpoints1 /= s1\n",
    "\tpoints2 /= s2\n",
    "\t# 奇异值分解\n",
    "\tU, S, Vt = np.linalg.svd(points1.T * points2)\n",
    "\tR = (U * Vt).T\n",
    "\treturn np.vstack([np.hstack(((s2/s1)*R, c2.T-(s2/s1)*R*c1.T)), np.matrix([0., 0., 1.])])\n",
    "\n",
    "\n",
    "def DrawConvexHull(img, points, color):\n",
    "\tpoints = cv2.convexHull(points)\n",
    "\tcv2.fillConvexPoly(img, points, color=color)\n",
    "\n",
    "\n",
    "def GetFaceMask(img, landmarks):\n",
    "\timg = np.zeros(img.shape[:2], dtype=np.float64)\n",
    "\tgroups = [ \n",
    "\t\tLEFT_EYE_POINTS + RIGHT_EYE_POINTS + LEFT_BROW_POINTS + RIGHT_BROW_POINTS,\n",
    "\t\tNOSE_POINTS + MOUTH_POINTS,\n",
    "\t\t]\n",
    "\tfor group in groups:\n",
    "\t\tDrawConvexHull(img, landmarks[group], color=1)\n",
    "\timg = np.array([img, img, img]).transpose((1, 2, 0))\n",
    "\timg = (cv2.GaussianBlur(img, (11, 11), 0) > 0) * 1.0\n",
    "\timg = cv2.GaussianBlur(img, (11, 11), 0)\n",
    "\treturn img\n",
    "\n",
    "\n",
    "def WarpImg(img, M, dshape):\n",
    "\toutput_img = np.zeros(dshape, dtype=img.dtype)\n",
    "\tcv2.warpAffine(img,\n",
    "\t\t\t\t   M[:2],\n",
    "\t\t\t\t   (dshape[1], dshape[0]),\n",
    "\t\t\t\t   dst=output_img,\n",
    "\t\t\t\t   borderMode=cv2.BORDER_TRANSPARENT,\n",
    "\t\t\t\t   flags=cv2.WARP_INVERSE_MAP)\n",
    "\treturn output_img\n",
    "\n",
    "\n",
    "def ModifyColor(img1, img2, landmarks1):\n",
    "\tblur_amount = 0.6 * np.linalg.norm(np.mean(landmarks1[LEFT_EYE_POINTS], axis=0) - np.mean(landmarks1[RIGHT_EYE_POINTS], axis=0))\n",
    "\tblur_amount = int(blur_amount)\n",
    "\tif blur_amount % 2 == 0:\n",
    "\t\tblur_amount += 1\n",
    "\timg1_blur = cv2.GaussianBlur(img1, (blur_amount, blur_amount), 0)\n",
    "\timg2_blur = cv2.GaussianBlur(img2, (blur_amount, blur_amount), 0)\n",
    "\timg2_blur += (128 * (img2_blur <= 1.0)).astype(img2_blur.dtype)\n",
    "\treturn (img2.astype(np.float64) * img1_blur.astype(np.float64) / img2_blur.astype(np.float64))\n",
    "\n",
    "\n",
    "def main(img1, img2):\n",
    "\tALIGN_POINTS = (LEFT_BROW_POINTS + RIGHT_EYE_POINTS + LEFT_EYE_POINTS + RIGHT_BROW_POINTS + NOSE_POINTS + MOUTH_POINTS)\n",
    "\timg1, landmarks1 = GetLandmarks(img1)\n",
    "\timg2, landmarks2 = GetLandmarks(img2)\n",
    "\tM = TransferPoints(landmarks1[ALIGN_POINTS], landmarks2[ALIGN_POINTS])\n",
    "\tmask = GetFaceMask(img2, landmarks2)\n",
    "\twarped_mask = WarpImg(mask, M, img1.shape)\n",
    "\tcombined_mask = np.max([GetFaceMask(img1, landmarks1), warped_mask], axis=0)\n",
    "\twarped_img2 = WarpImg(img2, M, img1.shape)\n",
    "\twarped_corrected_img2 = ModifyColor(img1, warped_img2, landmarks1)\n",
    "\toutput_img = img1 * (1.0 - combined_mask) + warped_corrected_img2 * combined_mask\n",
    "\tcv2.imwrite('output.jpg', output_img)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain('./results/1/1.png', './results/1/2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
