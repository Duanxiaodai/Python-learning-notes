{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 2.304 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "d:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator LinearSVC from version 0.19.1 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9 184]\n",
      " [ 25 174]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator MultinomialNB from version 0.19.1 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 25 168]\n",
      " [ 34 165]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "\n",
    "\n",
    "# 训练\n",
    "def train(normal_len, spam_len, fvs):\n",
    "\ttrain_labels = np.zeros(normal_len+spam_len)\n",
    "\ttrain_labels[normal_len:] = 1\n",
    "\t# SVM\n",
    "\tmodel1 = LinearSVC()\n",
    "\tmodel1.fit(fvs, train_labels)\n",
    "\tjoblib.dump(model1, 'LinearSVC.m')\n",
    "\t# 贝叶斯\n",
    "\tmodel2 = MultinomialNB()\n",
    "\tmodel2.fit(fvs, train_labels)\n",
    "\tjoblib.dump(model2, 'MultinomialNB.m')\n",
    "\n",
    "\n",
    "# 测试\n",
    "def test(model_path, fvs, labels):\n",
    "\tmodel = joblib.load(model_path)\n",
    "\tresult = model.predict(fvs)\n",
    "\tprint(confusion_matrix(labels, result))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\t# Part1\n",
    "\t'''\n",
    "\tstopWords = getStopWords(txt_path='./data/stopWords.txt')\n",
    "\twordsDict = wordsCount(filepath='./data/normal', stopWords=stopWords)\n",
    "\twordsDict = wordsCount(filepath='./data/spam', stopWords=stopWords, wordsDict=wordsDict)\n",
    "\tsaveDict(dict_data=wordsDict, savepath='./results.pkl')\n",
    "\t'''\n",
    "\t# Part2\n",
    "\t'''\n",
    "\twordsDict = readDict(filepath='./results.pkl')\n",
    "\twordsDict = getDictTopk(dict_data=wordsDict, topk=4000)\n",
    "\tsaveDict(dict_data=wordsDict, savepath='./wordsDict.pkl')\n",
    "\t'''\n",
    "\t# Part3\n",
    "\t'''\n",
    "\tnormal_path = './data/normal'\n",
    "\tspam_path = './data/spam'\n",
    "\twordsDict = readDict(filepath='./wordsDict.pkl')\n",
    "\tnormals = getFilesList(filepath=normal_path)\n",
    "\tspams = getFilesList(filepath=spam_path)\n",
    "\tfvs = []\n",
    "\tfor normal in normals:\n",
    "\t\tfv = extractFeatures(filepath=os.path.join(normal_path, normal), wordsDict=wordsDict, fv_len=4000)\n",
    "\t\tfvs.append(fv)\n",
    "\tnormal_len = len(fvs)\n",
    "\tfor spam in spams:\n",
    "\t\tfv = extractFeatures(filepath=os.path.join(spam_path, spam), wordsDict=wordsDict, fv_len=4000)\n",
    "\t\tfvs.append(fv)\n",
    "\tspam_len = len(fvs) - normal_len\n",
    "\tprint('[INFO]: Noraml-%d, Spam-%d' % (normal_len, spam_len))\n",
    "\tfvs = mergeFv(fvs)\n",
    "\tsaveNparray(np_array=fvs, savepath='./fvs_%d_%d.npy' % (normal_len, spam_len))\n",
    "\t'''\n",
    "\t# Part4\n",
    "\t'''\n",
    "\tfvs = readNparray(filepath='fvs_7063_7775.npy')\n",
    "\tnormal_len = 7063\n",
    "\tspam_len = 7775\n",
    "\ttrain(normal_len, spam_len, fvs)\n",
    "\t'''\n",
    "\t# Part5\n",
    "\twordsDict = readDict(filepath='./wordsDict.pkl')\n",
    "\ttest_normalpath = './data/test/normal'\n",
    "\ttest_spampath = './data/test/spam'\n",
    "\ttest_normals = getFilesList(filepath=test_normalpath)\n",
    "\ttest_spams = getFilesList(filepath=test_spampath)\n",
    "\tnormal_len = len(test_normals)\n",
    "\tspam_len = len(test_spams)\n",
    "\tfvs = []\n",
    "\tfor test_normal in test_normals:\n",
    "\t\tfv = extractFeatures(filepath=os.path.join(test_normalpath, test_normal), wordsDict=wordsDict, fv_len=4000)\n",
    "\t\tfvs.append(fv)\n",
    "\tfor test_spam in test_spams:\n",
    "\t\tfv = extractFeatures(filepath=os.path.join(test_spampath, test_spam), wordsDict=wordsDict, fv_len=4000)\n",
    "\t\tfvs.append(fv)\n",
    "\tfvs = mergeFv(fvs)\n",
    "\tlabels = np.zeros(normal_len+spam_len)\n",
    "\tlabels[normal_len:] = 1\n",
    "\ttest(model_path='LinearSVC.m', fvs=fvs, labels=labels)\n",
    "\ttest(model_path='MultinomialNB.m', fvs=fvs, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
